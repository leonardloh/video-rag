# Milvus Vector Database Specification

## Overview

Milvus is the vector database used for semantic similarity search over video captions in the VSS PoC. It stores embeddings generated by Gemini's `text-embedding-004` model and enables fast retrieval of relevant video segments based on natural language queries.

## Component Location

```
./src/db/milvus_client.py
```

---

## Collection Schema

The Milvus collection stores video caption documents with their embeddings and metadata.

```python
# Collection: vss_poc_captions
fields = [
    FieldSchema(name="id", dtype=DataType.VARCHAR, max_length=64, is_primary=True),
    FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=65535),
    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=768),
    FieldSchema(name="stream_id", dtype=DataType.VARCHAR, max_length=64),
    FieldSchema(name="chunk_idx", dtype=DataType.INT64),
    FieldSchema(name="start_time", dtype=DataType.VARCHAR, max_length=32),
    FieldSchema(name="end_time", dtype=DataType.VARCHAR, max_length=32),
    FieldSchema(name="start_pts", dtype=DataType.INT64),
    FieldSchema(name="end_pts", dtype=DataType.INT64),
    FieldSchema(name="cv_meta", dtype=DataType.VARCHAR, max_length=65535),
    FieldSchema(name="created_at", dtype=DataType.INT64),
]
```

### Field Descriptions

| Field | Type | Description |
|-------|------|-------------|
| `id` | VARCHAR(64) | Primary key, unique document identifier |
| `text` | VARCHAR(65535) | VLM-generated caption text |
| `embedding` | FLOAT_VECTOR(768) | Gemini text-embedding-004 vector |
| `stream_id` | VARCHAR(64) | Parent video stream identifier |
| `chunk_idx` | INT64 | Chunk sequence number within stream |
| `start_time` | VARCHAR(32) | Chunk start timestamp (HH:MM:SS format) |
| `end_time` | VARCHAR(32) | Chunk end timestamp (HH:MM:SS format) |
| `start_pts` | INT64 | Presentation timestamp start (nanoseconds) |
| `end_pts` | INT64 | Presentation timestamp end (nanoseconds) |
| `cv_meta` | VARCHAR(65535) | JSON-encoded CV detection metadata |
| `created_at` | INT64 | Unix timestamp of document creation |

---

## Index Configuration

```python
index_params = {
    "metric_type": "COSINE",
    "index_type": "IVF_FLAT",
    "params": {"nlist": 128}
}
```

### Index Parameters

| Parameter | Value | Description |
|-----------|-------|-------------|
| `metric_type` | COSINE | Cosine similarity for semantic search |
| `index_type` | IVF_FLAT | Inverted file index with flat quantization |
| `nlist` | 128 | Number of cluster units for IVF |

---

## Data Classes

### MilvusConfig

Configuration dataclass for Milvus connection settings.

```python
from dataclasses import dataclass


@dataclass
class MilvusConfig:
    """Milvus connection configuration."""
    host: str = "localhost"
    port: int = 19530
    collection_name: str = "vss_poc_captions"
    embedding_dim: int = 768
```

### VectorDocument

Dataclass representing a document stored in Milvus.

```python
from dataclasses import dataclass


@dataclass
class VectorDocument:
    """A document stored in Milvus."""
    id: str
    text: str
    embedding: list[float]
    stream_id: str
    chunk_idx: int
    start_time: str
    end_time: str
    start_pts: int = 0
    end_pts: int = 0
    cv_meta: str = ""
    created_at: int = 0
```

### SearchResult

Dataclass representing a search result from vector similarity search.

```python
from dataclasses import dataclass


@dataclass
class SearchResult:
    """Result from vector search."""
    document: VectorDocument
    score: float  # Cosine similarity score (0-1)
```

---

## MilvusClient API

The `MilvusClient` class provides all operations for interacting with the Milvus vector database.

```python
from dataclasses import dataclass
from typing import Optional, List
from datetime import datetime


class MilvusClient:
    """Client for Milvus vector database operations."""

    def __init__(self, config: MilvusConfig):
        """
        Initialize Milvus client.

        Args:
            config: Milvus connection configuration
        """
        pass

    async def connect(self) -> None:
        """Establish connection to Milvus."""
        pass

    async def close(self) -> None:
        """Close connection to Milvus."""
        pass

    async def ensure_collection(self) -> None:
        """Create collection if it doesn't exist."""
        pass

    async def insert(self, document: VectorDocument) -> str:
        """
        Insert a single document.

        Args:
            document: Document to insert

        Returns:
            Document ID
        """
        pass

    async def insert_batch(
        self,
        documents: list[VectorDocument],
        batch_size: int = 100
    ) -> list[str]:
        """
        Insert multiple documents in batches.

        Args:
            documents: Documents to insert
            batch_size: Number of documents per batch

        Returns:
            List of document IDs
        """
        pass

    async def search(
        self,
        query_embedding: list[float],
        top_k: int = 5,
        filter_expr: Optional[str] = None
    ) -> list[SearchResult]:
        """
        Search for similar documents.

        Args:
            query_embedding: Query vector (768 dimensions)
            top_k: Number of results to return
            filter_expr: Optional Milvus filter expression

        Returns:
            List of search results with scores

        Example filter expressions:
            - 'stream_id == "abc123"'
            - 'chunk_idx >= 5 && chunk_idx <= 10'
            - 'start_pts >= 1000000000'
        """
        pass

    async def search_by_stream(
        self,
        query_embedding: list[float],
        stream_id: str,
        top_k: int = 5
    ) -> list[SearchResult]:
        """Search within a specific stream."""
        pass

    async def search_by_time_range(
        self,
        query_embedding: list[float],
        start_time: str,
        end_time: str,
        top_k: int = 5
    ) -> list[SearchResult]:
        """Search within a time range."""
        pass

    async def get_by_id(self, doc_id: str) -> Optional[VectorDocument]:
        """Retrieve document by ID."""
        pass

    async def get_by_stream(
        self,
        stream_id: str,
        limit: int = 1000
    ) -> list[VectorDocument]:
        """Get all documents for a stream."""
        pass

    async def delete(self, doc_id: str) -> bool:
        """Delete document by ID."""
        pass

    async def delete_by_stream(self, stream_id: str) -> int:
        """Delete all documents for a stream. Returns count deleted."""
        pass

    async def drop_collection(self) -> None:
        """Drop the entire collection."""
        pass

    async def get_collection_stats(self) -> dict:
        """Get collection statistics."""
        pass
```

---

## Usage Examples

### Basic Connection and Search

```python
from poc.src.db.milvus_client import MilvusClient, MilvusConfig, VectorDocument

# Initialize client
config = MilvusConfig(
    host="localhost",
    port=19530,
    collection_name="vss_poc_captions"
)
client = MilvusClient(config)

# Connect and ensure collection exists
await client.connect()
await client.ensure_collection()

# Insert a document
doc = VectorDocument(
    id="chunk_001",
    text="A forklift moves pallets in the warehouse",
    embedding=[0.1, 0.2, ...],  # 768-dimensional vector
    stream_id="video_123",
    chunk_idx=0,
    start_time="00:00:00",
    end_time="00:01:00",
    start_pts=0,
    end_pts=60000000000,
    cv_meta='{"objects": ["forklift", "pallet"]}',
    created_at=1706400000
)
doc_id = await client.insert(doc)

# Search for similar documents
query_embedding = [0.15, 0.18, ...]  # 768-dimensional query vector
results = await client.search(query_embedding, top_k=5)

for result in results:
    print(f"Score: {result.score:.4f}")
    print(f"Text: {result.document.text}")
    print(f"Time: {result.document.start_time} - {result.document.end_time}")

# Close connection
await client.close()
```

### Filtered Search

```python
# Search within a specific stream
results = await client.search_by_stream(
    query_embedding=query_embedding,
    stream_id="video_123",
    top_k=10
)

# Search with custom filter expression
results = await client.search(
    query_embedding=query_embedding,
    top_k=5,
    filter_expr='stream_id == "video_123" && chunk_idx >= 5'
)

# Search by time range
results = await client.search_by_time_range(
    query_embedding=query_embedding,
    start_time="00:05:00",
    end_time="00:10:00",
    top_k=5
)
```

### Batch Operations

```python
# Batch insert documents
documents = [
    VectorDocument(
        id=f"chunk_{i:03d}",
        text=f"Caption for chunk {i}",
        embedding=embeddings[i],
        stream_id="video_123",
        chunk_idx=i,
        start_time=f"00:{i:02d}:00",
        end_time=f"00:{i+1:02d}:00",
        start_pts=i * 60000000000,
        end_pts=(i + 1) * 60000000000
    )
    for i in range(100)
]

doc_ids = await client.insert_batch(documents, batch_size=50)

# Get all documents for a stream
all_docs = await client.get_by_stream("video_123")

# Delete all documents for a stream
deleted_count = await client.delete_by_stream("video_123")
print(f"Deleted {deleted_count} documents")
```

### Collection Management

```python
# Get collection statistics
stats = await client.get_collection_stats()
print(f"Total documents: {stats.get('row_count', 0)}")

# Drop collection (use with caution)
await client.drop_collection()
```

---

## Configuration

### YAML Configuration

```yaml
# config/config.yaml
tools:
  vector_db:
    type: milvus
    params:
      host: !ENV ${MILVUS_HOST:localhost}
      port: !ENV ${MILVUS_PORT:19530}
      collection_name: "vss_poc_captions"
    tools:
      embedding: gemini_embedding
```

### Environment Variables

```bash
# .env
MILVUS_HOST=localhost
MILVUS_PORT=19530
```

### RAG Configuration Section

```yaml
# config/config.yaml
rag:
  enabled: true
  max_context_tokens: 100000

  # Vector DB (Milvus) - Required
  vector_db:
    enabled: true
    type: milvus
    host: !ENV ${MILVUS_HOST:localhost}
    port: !ENV ${MILVUS_PORT:19530}
    collection_name: "vss_poc_captions"

  # Hybrid Retrieval Configuration
  retrieval:
    mode: hybrid  # vector_only, graph_only, hybrid
    vector_weight: 0.6
    graph_weight: 0.4
    top_k: 5
    rerank: true
    temporal_boost: 1.2
```

---

## Docker Deployment

### Docker Compose Configuration

```yaml
# docker-compose.yaml
services:
  # Milvus Vector Database
  milvus-standalone:
    image: milvusdb/milvus:v2.5.4
    container_name: vss-milvus
    environment:
      ETCD_USE_EMBED: "true"
      ETCD_DATA_DIR: /var/lib/milvus/etcd
      COMMON_STORAGETYPE: local
    ports:
      - "19530:19530"  # gRPC
      - "9091:9091"    # HTTP
    volumes:
      - milvus_data:/var/lib/milvus
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5

volumes:
  milvus_data:
```

### Application Service Configuration

```yaml
# docker-compose.yaml (continued)
services:
  vss-poc:
    build:
      context: ./poc
      dockerfile: Dockerfile
    container_name: vss-poc
    environment:
      GEMINI_API_KEY: ${GEMINI_API_KEY}
      MILVUS_HOST: milvus-standalone
      MILVUS_PORT: 19530
    depends_on:
      milvus-standalone:
        condition: service_healthy
```

---

## Dependencies

```
# requirements.txt
pymilvus>=2.5.0
```

---

## Testing

### Unit Tests

```python
# tests/test_milvus_client.py
import pytest
from poc.src.db.milvus_client import MilvusClient, MilvusConfig, VectorDocument


class TestMilvusClient:
    """Unit tests for MilvusClient."""

    @pytest.fixture
    async def client(self):
        """Create test client."""
        config = MilvusConfig(
            host="localhost",
            port=19530,
            collection_name="test_collection"
        )
        client = MilvusClient(config)
        await client.connect()
        await client.ensure_collection()
        yield client
        await client.drop_collection()
        await client.close()

    async def test_insert_and_search(self, client):
        """Test inserting a document and searching for it."""
        doc = VectorDocument(
            id="test_001",
            text="Test caption",
            embedding=[0.1] * 768,
            stream_id="test_stream",
            chunk_idx=0,
            start_time="00:00:00",
            end_time="00:01:00"
        )
        await client.insert(doc)

        results = await client.search([0.1] * 768, top_k=1)
        assert len(results) == 1
        assert results[0].document.id == "test_001"

    async def test_search_with_filter(self, client):
        """Test searching with filter expression."""
        # Insert multiple documents
        for i in range(5):
            doc = VectorDocument(
                id=f"test_{i:03d}",
                text=f"Caption {i}",
                embedding=[0.1 + i * 0.01] * 768,
                stream_id="test_stream",
                chunk_idx=i,
                start_time=f"00:{i:02d}:00",
                end_time=f"00:{i+1:02d}:00"
            )
            await client.insert(doc)

        # Search with filter
        results = await client.search(
            [0.12] * 768,
            top_k=10,
            filter_expr='chunk_idx >= 2'
        )
        assert all(r.document.chunk_idx >= 2 for r in results)

    async def test_delete_by_stream(self, client):
        """Test deleting all documents for a stream."""
        # Insert documents
        for i in range(3):
            doc = VectorDocument(
                id=f"test_{i:03d}",
                text=f"Caption {i}",
                embedding=[0.1] * 768,
                stream_id="test_stream",
                chunk_idx=i,
                start_time="00:00:00",
                end_time="00:01:00"
            )
            await client.insert(doc)

        # Delete by stream
        deleted = await client.delete_by_stream("test_stream")
        assert deleted == 3

        # Verify deletion
        docs = await client.get_by_stream("test_stream")
        assert len(docs) == 0
```

### Integration Tests

```python
# tests/integration/test_milvus_integration.py
import pytest
from poc.src.db.milvus_client import MilvusClient, MilvusConfig, VectorDocument
from poc.src.models.gemini.gemini_embeddings import GeminiEmbeddings


class TestMilvusIntegration:
    """Integration tests for Milvus with Gemini embeddings."""

    @pytest.fixture
    async def setup(self):
        """Set up test environment."""
        config = MilvusConfig(
            host="localhost",
            port=19530,
            collection_name="integration_test"
        )
        client = MilvusClient(config)
        embeddings = GeminiEmbeddings(api_key="your_api_key")

        await client.connect()
        await client.ensure_collection()

        yield {"client": client, "embeddings": embeddings}

        await client.drop_collection()
        await client.close()

    async def test_full_ingestion_and_retrieval(self, setup):
        """Test full workflow: embed, insert, search."""
        client = setup["client"]
        embeddings = setup["embeddings"]

        # Generate embedding for caption
        caption = "A worker operates a forklift in the warehouse"
        embedding = await embeddings.embed_text(caption)

        # Insert document
        doc = VectorDocument(
            id="integration_001",
            text=caption,
            embedding=embedding,
            stream_id="integration_test",
            chunk_idx=0,
            start_time="00:00:00",
            end_time="00:01:00"
        )
        await client.insert(doc)

        # Search with query
        query = "forklift operation"
        query_embedding = await embeddings.embed_text(
            query,
            task_type="RETRIEVAL_QUERY"
        )
        results = await client.search(query_embedding, top_k=1)

        assert len(results) == 1
        assert "forklift" in results[0].document.text.lower()
```

---

## Integration with Hybrid Retrieval

Milvus is used as the vector search component in the hybrid retrieval system. See the [Hybrid Retrieval Specification](./hybrid-retrieval.md) for details on how vector and graph results are combined.

```python
# Example: Using Milvus in HybridRetriever
from poc.src.rag.hybrid_retrieval import HybridRetriever, HybridConfig, RetrievalMode

retriever = HybridRetriever(
    milvus_client=milvus_client,
    neo4j_client=neo4j_client,
    embeddings=embeddings,
    config=HybridConfig(
        mode=RetrievalMode.HYBRID,
        vector_weight=0.6,
        graph_weight=0.4,
        top_k=10
    )
)

# Retrieve context using hybrid approach
context = await retriever.retrieve(
    query="What happened with the forklift?",
    stream_id="video_123"
)
```

---

## Performance Considerations

### Milvus Limits and Optimization

| Aspect | Recommendation |
|--------|----------------|
| Batch Size | Insert in batches of 100-1000 documents |
| Index Building | Index is built automatically after insert |
| Query Latency | Typically < 100ms for 1M vectors |
| Memory | ~1GB RAM per 1M 768-dim vectors |

### Best Practices

1. **Use batch inserts** for multiple documents to reduce network overhead
2. **Create appropriate indexes** based on your query patterns
3. **Use filter expressions** to narrow search scope when possible
4. **Monitor collection statistics** to track growth and performance
5. **Clean up old data** using `delete_by_stream` when videos are removed
